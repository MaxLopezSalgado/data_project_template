{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Author: Your Name\n",
    "- First Commit: yyyy-mm-dd                      #folowing ISO  8601 Format\n",
    "- Last Commit: yyyy-mm-dd                       #folowing ISO  8601 Format\n",
    "- Description: This notebook is used to perform EDA on the \"xxxxx\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import folium\n",
    "from folium import plugins"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Gathering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv cleaned files \n",
    "df = pd.read_csv('../datasets/cleaned_df.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Assesing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look of the data´s shape\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look of the data´s info\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use describe method to get descriptive statistics\n",
    "display(df.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extracting and Plotting the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the dataframes we have, here are some potential information we can extract:\n",
    "\n",
    "**DataFrame 1: df**\n",
    "- Count of unique values.\n",
    "- Distribution of values.\n",
    "- Count of values.\n",
    "- Descriptive statistics of column´s values.\n",
    "- Time-based analysis of column´s values.\n",
    "- Geographic distribution of values on a map\n",
    "- Visualization of regions with a heatmap.\n",
    "\n",
    "**DataFrame 2: df2**\n",
    "- Count of unique values.\n",
    "- Distribution of values.\n",
    "- Count of values.\n",
    "- Descriptive statistics of column´s values.\n",
    "- Time-based analysis of column´s values.\n",
    "- Geographic distribution of values on a map\n",
    "- Visualization of regions with a heatmap.\n",
    "\n",
    "**DataFrame 3: df3**\n",
    "- Count of unique values.\n",
    "- Distribution of values.\n",
    "- Count of values.\n",
    "- Descriptive statistics of column´s values.\n",
    "- Time-based analysis of column´s values.\n",
    "- Geographic distribution of values on a map\n",
    "- Visualization of regions with a heatmap.\n",
    "\n",
    "**DataFrame 4: df4**\n",
    "- Count of unique values.\n",
    "- Distribution of values.\n",
    "- Count of values.\n",
    "- Descriptive statistics of column´s values.\n",
    "- Time-based analysis of column´s values.\n",
    "- Geographic distribution of values on a map\n",
    "- Visualization of regions with a heatmap."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame 1: Customer Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_column1 = cleaned_df['column1'].nunique()\n",
    "print(\"Number of unique values:\", column1) #-----> Change \"values\" for the variable name you want to analize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = cleaned_df['column1'].value_counts().reset_index()\n",
    "value_counts.columns = ['column1', 'Count']\n",
    "\n",
    "# Display the distribution of values\n",
    "print(\"\\nDistribution of values:\") #-----> Change \"values\" for the variable name you want to analize\n",
    "print(cleaned_df.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barplot of the distribution of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(cleaned_df['Count'][:10], labels=cleaned_df['column1'][:10], autopct='%1.1f%%')\n",
    "plt.title('Distribution of Values (Top 10)')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive statistics of Column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_column1 = cleaned_df['column1'].describe()\n",
    "\n",
    "print(\"Descriptive statistics of price:\")\n",
    "print(cleaned_df_column1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of values based on a column or several columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df[['column1', 'column2', 'column3', 'column4']].hist(figsize=(12, 6))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barplot of the distribution of values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_counts = df['column1'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "cleaned_df_counts.plot(kind='bar')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Number of Cities')\n",
    "plt.title('Distribution of Cities across States')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyses specific to geolocation data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographic distribution of values (i.e. customers, start/end points) on a map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address the long runtime and the large number of locations, consider using a random sample of the data. This will allow you to work with a smaller subset of the data, making it faster to merge and plot on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to import folium library\n",
    "# In case you haven`t do:\n",
    "# import folium\n",
    "\n",
    "# Randomly sample the geolocation DataFrame\n",
    "sampled_geolocation = geolocation.sample(n=250) \n",
    "\n",
    "# Randomly sample the cleaned_customers DataFrame\n",
    "sampled_cleaned_customers = cleaned_df.sample(n=250) \n",
    "\n",
    "# Merge the geolocation DataFrame with the cleaned_customers DataFrame using the common column 'customer_city'.\n",
    "merged_df = pd.merge(sampled_geolocation, sampled_cleaned_customers, left_on='geolocation_city', right_on='customer_city', how='inner')\n",
    "\n",
    "# Create a map object centered at a specific latitude and longitude you want, for example:\n",
    "map = folium.Map(location=[-12.257569734193066, -53.113064202406306], zoom_start=4)\n",
    "\n",
    "# Iterate over the aggregated data and add markers for each location\n",
    "for index, row in merged_df.iterrows():\n",
    "    lat = row['geolocation_lat']\n",
    "    lon = row['geolocation_lng']\n",
    "    city = row['geolocation_city']\n",
    "    marker = folium.Marker(location=[lat, lon], popup=city)\n",
    "    marker.add_to(map)\n",
    "\n",
    "# save the map\n",
    "map.save('map.html')\n",
    "\n",
    "# Display the map\n",
    "map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap - Regions with the highest concentration of values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before, consider using a random sample of the data in case the df are too big, to avoid running errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'customer_city' and count the occurrences\n",
    "heatmap_city_counts = sampled_cleaned_customers['customer_city'].value_counts().reset_index()\n",
    "heatmap_city_counts.columns = ['customer_city', 'count']\n",
    "\n",
    "# Convert 'customer_city' to lowercase for consistency\n",
    "heatmap_city_counts['customer_city'] = heatmap_city_counts['customer_city'].str.lower()\n",
    "\n",
    "# Merge with the 'sampled_geolocation' DataFrame\n",
    "heatmap_merged_df = pd.merge(sampled_geolocation, heatmap_city_counts, left_on='geolocation_city', right_on='customer_city', how='inner')\n",
    "\n",
    "# Create a map object centered at a specific latitude and longitude\n",
    "map_heatmap = folium.Map(location=[-12.257569734193066, -53.113064202406306], zoom_start=4)\n",
    "\n",
    "# Create a HeatMap layer using the aggregated latitude and longitude coordinates\n",
    "heatmap_data = heatmap_merged_df[['geolocation_lat', 'geolocation_lng', 'count']].values\n",
    "heatmap_layer = plugins.HeatMap(heatmap_data)\n",
    "\n",
    "# Add the HeatMap layer to the map\n",
    "heatmap_layer.add_to(map_heatmap)\n",
    "\n",
    "# Save the map as an HTML file\n",
    "map_heatmap.save('heatmap.html')\n",
    "\n",
    "# Display the map\n",
    "map_heatmap\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
